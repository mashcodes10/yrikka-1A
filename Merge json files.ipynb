{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXRVt1LZEDKEcj10nxMpVP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import json\n","\n","# === FILE PATHS ===\n","path1 = \"instances_default_first.json\"\n","path2 = \"instances_default_second.json\"\n","path3 = \"instances_default_third.json\"\n","\n","# === LOAD FILES ===\n","with open(path1) as f:\n","    d1 = json.load(f)\n","\n","with open(path2) as f:\n","    d2 = json.load(f)\n","\n","with open(path3) as f:\n","    d3 = json.load(f)\n","\n","print(\"Loaded all three JSON files.\")\n","\n","# === NORMALIZE FILENAMES ===\n","def normalize_filenames(dataset):\n","    for img in dataset[\"images\"]:\n","        if img[\"file_name\"].startswith(\"images/\"):\n","            img[\"file_name\"] = img[\"file_name\"][len(\"images/\"):]\n","    return dataset\n","\n","d3 = normalize_filenames(d3)\n","print(\"Filenames in d3 normalized.\")\n","\n","# === FIX CATEGORY IDS ===\n","ref_cat_name_to_id = {c[\"name\"]: c[\"id\"] for c in d1[\"categories\"]}\n","\n","def fix_category_ids(dataset, ref_map, label=\"\"):\n","    local_id_to_name = {c[\"id\"]: c[\"name\"] for c in dataset[\"categories\"]}\n","\n","    for ann in dataset[\"annotations\"]:\n","        name = local_id_to_name[ann[\"category_id\"]]\n","        ann[\"category_id\"] = ref_map[name]\n","\n","    dataset[\"categories\"] = d1[\"categories\"]\n","\n","    print(f\"\\n--- Category IDs for {label} ---\")\n","    for c in dataset[\"categories\"]:\n","        print(f\"ID {c['id']}: {c['name']}\")\n","\n","    return dataset\n","\n","d1 = fix_category_ids(d1, ref_cat_name_to_id, label=\"d1 (reference)\")\n","d2 = fix_category_ids(d2, ref_cat_name_to_id, label=\"d2 (after fix)\")\n","d3 = fix_category_ids(d3, ref_cat_name_to_id, label=\"d3 (after fix)\")\n","\n","print(\"\\nCategory IDs normalized for all datasets.\")\n","\n","# === MERGE WITH PROPER ID REMAPPING ===\n","def merge_datasets(base_dataset, new_dataset, label=\"\"):\n","    \"\"\"Merge new_dataset into base_dataset with proper ID remapping\"\"\"\n","\n","    # Create filename -> image mapping for base dataset\n","    base_filename_to_image = {img[\"file_name\"]: img for img in base_dataset[\"images\"]}\n","\n","    # Track image ID mappings: old_id -> new_id\n","    image_id_mapping = {}\n","\n","    # Get max IDs from base dataset\n","    max_img_id = max([img[\"id\"] for img in base_dataset[\"images\"]]) if base_dataset[\"images\"] else 0\n","    max_ann_id = max([ann[\"id\"] for ann in base_dataset[\"annotations\"]]) if base_dataset[\"annotations\"] else 0\n","\n","    # Process images from new dataset\n","    images_to_add = []\n","    for img in new_dataset[\"images\"]:\n","        if img[\"file_name\"] in base_filename_to_image:\n","            # Image already exists - use existing ID\n","            old_id = img[\"id\"]\n","            existing_img = base_filename_to_image[img[\"file_name\"]]\n","            image_id_mapping[old_id] = existing_img[\"id\"]\n","            # print(f\"Image '{img['file_name']}' already exists with ID {existing_img['id']}\")\n","        else:\n","            # New image - assign new ID\n","            old_id = img[\"id\"]\n","            max_img_id += 1\n","            img[\"id\"] = max_img_id\n","            image_id_mapping[old_id] = max_img_id\n","            images_to_add.append(img)\n","\n","    # Process annotations with remapped image IDs\n","    for ann in new_dataset[\"annotations\"]:\n","        # Shift annotation ID\n","        max_ann_id += 1\n","        ann[\"id\"] = max_ann_id\n","\n","        # Remap image_id\n","        if ann[\"image_id\"] in image_id_mapping:\n","            ann[\"image_id\"] = image_id_mapping[ann[\"image_id\"]]\n","        else:\n","            print(f\"WARNING: Annotation {ann['id']} references unknown image_id {ann['image_id']}\")\n","\n","    # Add to base dataset\n","    base_dataset[\"images\"].extend(images_to_add)\n","    base_dataset[\"annotations\"].extend(new_dataset[\"annotations\"])\n","\n","    print(f\"{label}: Added {len(images_to_add)} new images, {len(new_dataset['annotations'])} annotations\")\n","\n","    return base_dataset\n","\n","# Start with d1 as base\n","merged = {\n","    \"categories\": d1[\"categories\"],\n","    \"images\": d1[\"images\"][:],  # Copy\n","    \"annotations\": d1[\"annotations\"][:]  # Copy\n","}\n","\n","# Merge d2\n","merged = merge_datasets(merged, d2, label=\"Merging d2\")\n","\n","# Merge d3\n","merged = merge_datasets(merged, d3, label=\"Merging d3\")\n","\n","print(\"\\nMerged all datasets with correct category + annotation + image IDs.\")\n","\n","# Save intermediate merged CVAT file\n","output_path = \"merged_cvat_all.json\"\n","with open(output_path, \"w\") as f:\n","    json.dump(merged, f, indent=4)\n","\n","print(\"Saved merged CVAT file →\", output_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vI8NbwVnMfMS","executionInfo":{"status":"ok","timestamp":1763494524115,"user_tz":300,"elapsed":209,"user":{"displayName":"Mildred Nwachukwu-Innocent","userId":"13098015916600848607"}},"outputId":"ccafed5f-1b55-4296-8e21-4f7040874625"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded all three JSON files.\n","Filenames in d3 normalized.\n","\n","--- Category IDs for d1 (reference) ---\n","ID 1: potted plant\n","ID 2: vase\n","ID 3: cup\n","ID 4: book\n","ID 5: chair\n","\n","--- Category IDs for d2 (after fix) ---\n","ID 1: potted plant\n","ID 2: vase\n","ID 3: cup\n","ID 4: book\n","ID 5: chair\n","\n","--- Category IDs for d3 (after fix) ---\n","ID 1: potted plant\n","ID 2: vase\n","ID 3: cup\n","ID 4: book\n","ID 5: chair\n","\n","Category IDs normalized for all datasets.\n","Merging d2: Added 0 new images, 955 annotations\n","Merging d3: Added 0 new images, 1520 annotations\n","\n","Merged all datasets with correct category + annotation + image IDs.\n","Saved merged CVAT file → merged_cvat_all.json\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0_lMA3VMVanl"},"execution_count":null,"outputs":[]}]}